# Retrieval + Guardrails â€“ Lean FastAPI Service

> **Production-ready retrieval-augmented answering service** with built-in safety guardrails, monitoring, and modular architecture.

## ğŸš€ Quick Summary

**What it does**: A FastAPI service that answers questions using TF-IDF retrieval over a curated corpus, with denylist guardrails and real-time monitoring.

**Key highlights**:
- âš¡ **Fast setup**: 3 commands to run (venv, pip install, uvicorn)
- ğŸ§ª **Fully tested**: 12 integration tests, all passing
- ğŸ“Š **Observable**: Built-in metrics endpoint + latency headers
- ğŸ›¡ï¸ **Safe**: Guardrail blocks 10 harmful query types
- ğŸ¯ **Modular**: Clean architecture with 17 modules across 6 layers
- ğŸ“– **Well-documented**: Comprehensive design rationale included

**Time to first answer**: < 2 minutes from clone to running service

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Quick Start](#quick-start)
- [API Documentation](#api-documentation)
- [Design Decisions](#design-decisions)
- [Testing](#testing)
- [Monitoring](#monitoring)
- [Project Structure](#project-structure-modularized)
- [Future Improvements](#future-improvements)

---

## ğŸ¯ Overview

This project implements a **minimal retrieval-augmented answering service** that demonstrates production best practices:

- âœ… **Small text corpus** (12 curated snippets covering ML/AI concepts)
- âœ… **FastAPI endpoints** with typed request/response validation
- âœ… **One practical guardrail** (denylist) with clear refusal path
- âœ… **Two retrieval configs** for comparison (cosine vs dot-product)
- âœ… **Lightweight monitoring** (latency p95, hit-rate, drift detection)
- âœ… **Modular architecture** following clean code principles

**Built for**: Job interview technical assessment  
**Tech Stack**: FastAPI, scikit-learn, Pydantic, pytest

---

## âœ¨ Features

### Core Functionality

- **POST /answer** - Retrieval-augmented question answering
  - Takes a query, returns top-k snippets + synthesized answer
  - Supports two retrieval strategies (cosine/dot-product)
  - Detects and flags low-confidence results

- **GET /metrics** - Real-time monitoring dashboard
  - Request counts (total, blocked, low-confidence)
  - Latency stats (mean, p95)
  - Drift indicators

### Safety & Quality

- **Denylist Guardrail** - Blocks harmful queries (deterministic, auditable)
- **Low-Confidence Detection** - Flags poor retrieval matches
- **Input Validation** - Automatic via Pydantic schemas

### Retrieval Configs

| Config | Metric | Top-K | Use Case |
|--------|--------|-------|----------|
| **Default (A)** | Cosine | 3 | Precision-oriented, normalizes document length |
| **Contrast (B)** | Dot-product | 5 | Recall-oriented, considers magnitude |

---

## ğŸ—ï¸ Architecture

### Modular Design (Clean Architecture)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Layer     â”‚  â† Thin controllers (routes/)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service Layer   â”‚  â† Business logic (services/)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Domain Models   â”‚  â† Core entities (models/)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Infrastructure  â”‚  â† Retrieval, storage, utils
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Patterns**:
- âœ… Service Layer (business logic isolation)
- âœ… Repository Pattern (data access abstraction)
- âœ… Dependency Injection (FastAPI Depends)
- âœ… Protocol-based extensibility (guardrails)

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+ 
- pip (Python package manager)

### Installation & Running

```bash
# 1. Create virtual environment
python -m venv venv

# 2. Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the server
uvicorn app.main:app --reload --port 8000
```

**Server will start at**: http://127.0.0.1:8000

### First Steps

1. **Interactive API Docs**: Open http://127.0.0.1:8000/docs
2. **Health Check**: `curl http://127.0.0.1:8000/`
3. **Try a Query**: See [API Examples](#api-examples) below

---

## ğŸ“š API Documentation

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Health check |
| `/answer` | POST | Query answering with retrieval |
| `/metrics` | GET | Monitoring metrics |
| `/docs` | GET | Interactive Swagger UI |

### API Examples

#### 1ï¸âƒ£ Health Check

```bash
curl http://127.0.0.1:8000/
```

**Response:**
```json
{
  "service": "mini-rag",
  "status": "healthy",
  "endpoints": ["/answer", "/metrics", "/docs"]
}
```

---

#### 2ï¸âƒ£ POST /answer - Default Config (Cosine, k=3)

```bash
curl -X POST "http://127.0.0.1:8000/answer" \
  -H "Content-Type: application/json" \
  -d '{"query": "What is cosine similarity?"}'
```

**Request Schema:**
```json
{
  "query": "string (required, min_length=1)",
  "config": "cos3 | dot5 (optional)",
  "top_k": "integer 1-10 (optional)"
}
```

**Response:**
```json
{
  "answer": "Based on available information: Cosine similarity measures the angle between two vectors, normalizing for magnitude...",
  "snippets": [
    {
      "id": "s1",
      "text": "Cosine similarity measures the angle between...",
      "score": 0.68
    },
    {
      "id": "s12",
      "text": "Vector normalization (L2) scales vectors...",
      "score": 0.42
    }
  ],
  "config_used": "cosine,k=3",
  "low_confidence": false
}
```

---

#### 3ï¸âƒ£ POST /answer - Dot-Product Config (k=5)

```bash
curl -X POST "http://127.0.0.1:8000/answer" \
  -H "Content-Type: application/json" \
  -d '{"query": "TF-IDF vectorization", "config": "dot5"}'
```

---

#### 4ï¸âƒ£ POST /answer - Custom top_k

```bash
curl -X POST "http://127.0.0.1:8000/answer" \
  -H "Content-Type: application/json" \
  -d '{"query": "FastAPI middleware", "top_k": 2}'
```

---

#### 5ï¸âƒ£ POST /answer - Guardrail Block (Returns 400)

```bash
curl -X POST "http://127.0.0.1:8000/answer" \
  -H "Content-Type: application/json" \
  -d '{"query": "instructions for illegal activity"}'
```

**Response (HTTP 400):**
```json
{
  "detail": "Query blocked by guardrail. Matched denied phrase: 'instructions for illegal'"
}
```

---

#### 6ï¸âƒ£ GET /metrics - Monitoring Dashboard

```bash
curl http://127.0.0.1:8000/metrics
```

**Response:**
```json
{
  "total_requests": 42,
  "denylist_hits": 2,
  "low_confidence_count": 5,
  "latency_ms_mean": 12.4,
  "latency_ms_p95": 18.7,
  "low_confidence_rate": 0.119
}
```

---

## ğŸ¯ Design Decisions

### 1. Why TF-IDF for Retrieval?

**Chosen**: TF-IDF vectorization with scikit-learn

**Rationale**:
- âœ… **Zero external dependencies** - Built into scikit-learn
- âœ… **Deterministic** - Same query always returns same results
- âœ… **Fast cold-start** - No model downloads or GPU needed
- âœ… **Easy to debug** - Interpretable scores
- âœ… **Swappable** - Can upgrade to embeddings without API changes

**Reference**: [scikit-learn TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)

---

### 2. Why Cosine vs Dot-Product Comparison?

| Metric | Normalization | Bias | Best For |
|--------|---------------|------|----------|
| **Cosine** | L2-normalized | No length bias | Mixed document lengths, precision |
| **Dot-product** | Raw TF-IDF | Favors longer docs | Understanding magnitude effects |

**Cosine (Default)**: Measures **angle** between vectors â†’ document length doesn't dominate  
**Dot-product (Contrast)**: Considers **magnitude** â†’ shows recall/verbosity trade-off

This comparison demonstrates understanding of similarity metrics and their practical implications.

**Reference**: [Cosine Similarity - Wikipedia](https://en.wikipedia.org/wiki/Cosine_similarity)

---

### 3. Why Denylist Guardrail?

**Chosen**: Simple phrase-based blocklist

**Rationale**:
- âœ… **Deterministic** - Predictable, auditable behavior
- âœ… **Zero-ML** - No model training or maintenance
- âœ… **Fast** - O(n) substring matching
- âœ… **Transparent** - Easy to explain refusals
- âœ… **Extensible** - Can add more sophisticated checks later

**Practical**: Good baseline before adding heavier policy models or rate limits.

**Reference**: [Google SRE - Monitoring Distributed Systems](https://sre.google/sre-book/monitoring-distributed-systems/)

---

### 4. Why These Monitoring Metrics?

#### Latency P95 (95th Percentile)

- **Why p95 not mean?** Tail latency affects user experience more than average
- **SLO compliance**: Standard SRE practice for service health
- **Captured via**: FastAPI middleware on every request

#### Low-Confidence Rate

- **Purpose**: Cheap drift detection proxy
- **Signal**: If rate climbs â†’ corpus stale or config mismatch
- **Threshold**: Configurable via `LOW_CONF_THRESHOLD` env var

**Reference**: [SRE Golden Signals](https://sre.google/sre-book/monitoring-distributed-systems/)

---

### 5. Why Modular Architecture?

**Pattern**: Clean Architecture with layered design

**Benefits**:
- âœ… **Testability** - Each layer tests in isolation
- âœ… **Maintainability** - Clear boundaries, single responsibility
- âœ… **Scalability** - Easy to add features or swap implementations
- âœ… **Production-ready** - Follows industry best practices

**Layers**:
1. **API** (routes/) - HTTP handling
2. **Service** (services/) - Business logic
3. **Domain** (models/) - Core entities
4. **Infrastructure** (retrieval/, core/) - Technical concerns

**Reference**: [FastAPI - Bigger Applications](https://fastapi.tiangolo.com/tutorial/bigger-applications/)

---

## Project Structure (Modularized)

```
mini-rag/
â”œâ”€ app/
â”‚  â”œâ”€ main.py                      # FastAPI app factory + lifespan management
â”‚  â”œâ”€ routes/
â”‚  â”‚  â””â”€ answer.py                 # API endpoints (thin layer)
â”‚  â”œâ”€ core/
â”‚  â”‚  â”œâ”€ config.py                 # Environment configuration
â”‚  â”‚  â”œâ”€ dependencies.py           # FastAPI dependency injection
â”‚  â”‚  â””â”€ metrics.py                # Metrics middleware + collector
â”‚  â”œâ”€ services/                    # Business logic layer
â”‚  â”‚  â”œâ”€ retrieval_service.py      # Retrieval orchestration
â”‚  â”‚  â”œâ”€ guardrail_service.py      # Guardrail orchestration
â”‚  â”‚  â”œâ”€ answer_service.py         # Answer synthesis
â”‚  â”‚  â””â”€ metrics_service.py        # Metrics computation
â”‚  â”œâ”€ models/                      # Domain models (internal)
â”‚  â”‚  â”œâ”€ document.py               # Document & ScoredDocument
â”‚  â”‚  â”œâ”€ metrics.py                # MetricsSnapshot
â”‚  â”‚  â””â”€ retrieval_config.py       # RetrievalConfig
â”‚  â”œâ”€ guardrails/
â”‚  â”‚  â””â”€ denylist.py               # Denylist implementation
â”‚  â”œâ”€ retrieval/
â”‚  â”‚  â”œâ”€ index.py                  # TF-IDF vectorization & scoring
â”‚  â”‚  â”œâ”€ repository.py             # Corpus repository pattern
â”‚  â”‚  â””â”€ corpus.py                 # Corpus initialization
â”‚  â”œâ”€ schemas/
â”‚  â”‚  â””â”€ answer.py                 # Pydantic API schemas
â”‚  â””â”€ utils/
â”‚     â”œâ”€ text.py                   # Text processing utilities
â”‚     â””â”€ scoring.py                # Math & scoring helpers
â”œâ”€ tests/
â”‚  â””â”€ test_answer.py               # Integration tests
â”œâ”€ requirements.txt
â”œâ”€ .env.example
â”œâ”€ README.md
â””â”€ Makefile
```

### Architecture Layers

**1. API Layer** (`routes/`)
- Thin controllers that delegate to services
- Uses dependency injection for clean testability

**2. Service Layer** (`services/`)
- Business logic and orchestration
- Independent of FastAPI/HTTP concerns
- Easy to test in isolation

**3. Domain Models** (`models/`)
- Internal data structures
- Separate from API schemas for flexibility

**4. Data Access** (`retrieval/repository.py`)
- Repository pattern for corpus access
- Easy to swap implementations (DB, file, etc.)

**5. Infrastructure** (`core/`)
- Cross-cutting concerns (config, metrics, DI)
- Middleware and framework integration

**6. Utilities** (`utils/`)
- Shared helpers without business logic
- Reusable across modules

---

## ğŸ§ª Testing

### Running Tests

```powershell
# Run all tests with verbose output
pytest -v

# Run with coverage report
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/test_answer.py -v
```

### Test Coverage

**12 Integration Tests** covering:

| Test Category | Coverage |
|--------------|----------|
| **Health Check** | `/health` endpoint |
| **Retrieval Configs** | Cosine (k=3) and Dot-product (k=5) |
| **Guardrails** | Denylist blocking with 3 harmful phrases |
| **Metrics** | `/metrics` endpoint and response headers |
| **Validation** | Empty queries, invalid configs |
| **Performance** | Latency tracking middleware |

### Expected Test Output

```
tests/test_answer.py::test_health_check PASSED                          [  8%]
tests/test_answer.py::test_answer_endpoint_success PASSED               [ 16%]
tests/test_answer.py::test_answer_with_cosine_config PASSED             [ 25%]
tests/test_answer.py::test_answer_with_dot5_config PASSED               [ 33%]
tests/test_answer.py::test_guardrail_blocks_harmful_query PASSED        [ 41%]
tests/test_answer.py::test_guardrail_blocks_weapon_query PASSED         [ 50%]
tests/test_answer.py::test_guardrail_blocks_fraud_query PASSED          [ 58%]
tests/test_answer.py::test_metrics_endpoint PASSED                      [ 66%]
tests/test_answer.py::test_empty_query_validation PASSED                [ 75%]
tests/test_answer.py::test_invalid_config PASSED                        [ 83%]
tests/test_answer.py::test_latency_header_present PASSED                [ 91%]
tests/test_answer.py::test_low_confidence_detection PASSED              [100%]

======================== 12 passed in 2.47s =========================
```

### Test Architecture

- Uses **TestClient** with lifespan context for proper initialization
- Tests actual HTTP endpoints (integration tests, not unit tests)
- Validates both happy paths and error cases
- Checks guardrail behavior with multiple blocked phrases
- Verifies metrics accumulation and calculation

---

## ğŸ“Š Monitoring

### Accessing Metrics

```bash
curl http://127.0.0.1:8000/metrics
```

### Available Metrics

| Metric | Type | Description | Use Case |
|--------|------|-------------|----------|
| **total_requests** | Counter | Total `/answer` calls | Traffic volume |
| **denylist_hits** | Counter | Blocked queries | Safety monitoring |
| **low_confidence_count** | Counter | Queries with score < 0.15 | Quality tracking |
| **latency_ms_mean** | Gauge | Average response time | Performance baseline |
| **latency_ms_p95** | Gauge | 95th percentile latency | Tail latency SLO |
| **low_confidence_rate** | Gauge | Ratio of low-confidence queries | Drift detection |

### Response Headers

Every `/answer` request includes:

```
X-Latency-Ms: 12.34
```

**Use Case**: Client-side latency tracking without querying `/metrics`

### Monitoring in Action

**Example Metrics Response:**

```json
{
  "total_requests": 150,
  "denylist_hits": 4,
  "low_confidence_count": 12,
  "latency_ms_mean": 11.2,
  "latency_ms_p95": 18.7,
  "low_confidence_rate": 0.08
}
```

**Interpretation**:
- 150 queries processed
- 4 blocked by guardrail (2.7% block rate)
- 12 had low confidence (8% drift signal)
- p95 latency = 18.7ms (good performance)

### Alert Recommendations

| Metric | Threshold | Action |
|--------|-----------|--------|
| `latency_ms_p95` | > 100ms | Check corpus size or add caching |
| `low_confidence_rate` | > 0.3 | Review corpus quality or add snippets |
| `denylist_hits` | Spike | Investigate attack patterns |

---

## Configuration

Environment variables (`.env`):

| Variable | Default | Description |
|----------|---------|-------------|
| `CONFIG_DEFAULT` | `cosine` | Default similarity metric (`cosine` or `dot`) |
| `TOP_K_DEFAULT` | `3` | Default number of snippets to retrieve |
| `LOW_CONF_THRESHOLD` | `0.15` | Score threshold for low-confidence detection |
| `HOST` | `0.0.0.0` | Server host |
| `PORT` | `8000` | Server port |

---

## Future Improvements

1. **Embeddings**: Swap TF-IDF for sentence embeddings (e.g., `sentence-transformers`)
2. **Persistence**: Save TF-IDF artifacts to disk for faster cold-starts
3. **Evaluation**: Add offline hit@k / MRR tests with labeled queries
4. **More guardrails**: Rate limits, streaming filters, policy models
5. **LLM integration**: Replace naive answer synthesis with actual generation

---

## References

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [scikit-learn TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
- [12-Factor App: Config](https://12factor.net/config)
- [Google SRE: Monitoring](https://sre.google/sre-book/monitoring-distributed-systems/)
- [Cosine Similarity (Wikipedia)](https://en.wikipedia.org/wiki/Cosine_similarity)

---

## License

MIT
